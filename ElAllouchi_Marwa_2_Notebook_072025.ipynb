{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "460aabe4-2c0a-4aa9-a38a-3869b2efce92",
   "metadata": {},
   "source": [
    "# Importation de bibliothèques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6336bc7-51a4-4cdf-852f-442df985ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a78d3-1af9-4d23-81ad-145193c0405e",
   "metadata": {},
   "source": [
    "# Partie 1: \n",
    "## Etape 1 : Chargement et aperçu des données\n",
    "Le fichier CSV a été chargé dans un DataFrame df1 à l’aide de pd.read_csv(). Un aperçu des 10 premières lignes a été affiché pour avoir une première idée de la structure : chaque ligne représente un pays.\n",
    "\n",
    "## Étape 2 : Analyse préliminaire\n",
    "Dimensions du jeu de données\n",
    "\n",
    "On utilise .shape pour afficher le nombre total de lignes et de colonnes. Cela permet de connaître la taille globale du DataFrame.\n",
    "\n",
    "-Recherche de doublons\n",
    "\n",
    "Grâce à .duplicated().sum(), on a identifié le nombre de doublons complets.\n",
    "\n",
    "Si des doublons existent, ils sont supprimés avec .drop_duplicates().\n",
    "\n",
    "-Valeurs manquantes\n",
    "\n",
    "-La proportion de valeurs manquantes par colonne a été calculée avec .isna().mean(). Cela permet de repérer les colonnes peu informatives ou inexploitables.\n",
    "\n",
    "-Colonnes inutiles\n",
    "\n",
    "On a vérifié si une colonne appelée 'Unnamed: 31' (souvent issue d’un export Excel mal nettoyé) est présente. Si elle est entièrement vide ou non pertinente, elle est supprimée.\n",
    "\n",
    "-Types des données\n",
    "\n",
    "On examine les types (dtypes) pour identifier les colonnes numériques et catégorielles.\n",
    "\n",
    "-Statistiques descriptives\n",
    "\n",
    "Pour les colonnes numériques, .describe() donne des informations comme la moyenne, l’écart-type, les quartiles, etc.\n",
    "\n",
    "-Occurrences des catégories\n",
    "\n",
    "Pour chaque colonne de type object, on affiche les occurrences de chaque valeur avec value_counts(). Cela aide à comprendre la distribution des données textuelles.\n",
    "## Étape 3 : Nettoyage approfondi\n",
    "Inspection de la colonne \"Region\"\n",
    "\n",
    "On utilise .unique() pour afficher toutes les valeurs uniques dans la colonne \"Region\".\n",
    "\n",
    "-Identification des faux pays\n",
    "\n",
    "Les \"faux pays\" sont ceux qui n’ont pas de région renseignée (NaN dans \"Region\"). On extrait leur code via la colonne \"Country Code\".\n",
    "\n",
    "-Filtrage du DataFrame\n",
    "\n",
    "On crée un nouveau DataFrame df_vrai_pays en excluant les lignes correspondant aux faux pays, à l’aide d’un filtre sur \"Country Code\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69223207-afb6-47cf-9069-b4127643c5d4",
   "metadata": {},
   "source": [
    "## Fichier EdStatsCountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da866c5-5ea2-4339-be8d-7d14327a0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier\n",
    "df1 = pd.read_csv('EdStatsCountry.csv')\n",
    "\n",
    "# Aperçu des premières lignes : un ligne = un pays\n",
    "display(df1.head(10))\n",
    "\n",
    "# 1. Nombre de lignes et colonnes\n",
    "dim_df1 = df1.shape\n",
    "print(\"Le nombre de lignes et de colonnes dans df1 est :\", dim_df1)\n",
    "\n",
    "# 2. Nombre de doublons\n",
    "df1_doublons = df1.duplicated().sum()\n",
    "print(\"Le nombre de doublons dans df1 est :\", df1_doublons)\n",
    "\n",
    "# 3. Suppression des doublons (si présents)\n",
    "if df1_doublons > 0:\n",
    "    df1 = df1.drop_duplicates()\n",
    "\n",
    "# 4. Proportion de valeurs manquantes par colonne\n",
    "print(\"Proportion de valeurs manquantes par colonne :\")\n",
    "print(df1.isna().mean().sort_values(ascending=False))\n",
    "\n",
    "#  5. Identifier les colonnes inutilisables (ex. entièrement vides)\n",
    "print(\"Types des colonnes :\")\n",
    "print(df1.dtypes)\n",
    "\n",
    "# Suppression des colonnes vides ou sans information utile\n",
    "if 'Unnamed: 31' in df1.columns:\n",
    "    display(df1['Unnamed: 31'])  # Vérification visuelle (souvent NaN)\n",
    "    df1 = df1.drop(columns=['Unnamed: 31'])\n",
    "\n",
    "# 6. Statistiques descriptives pour les colonnes numériques\n",
    "print(\"Statistiques descriptives des colonnes numériques :\")\n",
    "print(df1.describe())\n",
    "\n",
    "# 7. Occurrences pour chaque valeur des colonnes catégorielles\n",
    "print(\"Valeurs uniques pour les colonnes catégorielles :\")\n",
    "for col in df1.select_dtypes(include='object').columns:\n",
    "    print(f\"Occurrences pour la colonne '{col}' :\")\n",
    "    print(df1[col].value_counts(dropna=False))  # inclut les NaN\n",
    "    print(\"-------------\")\n",
    "## Etape 3 : nettoyage ###\n",
    "# Vérifions les valeurs uniques dans la colonne \"Region\"\n",
    "print(df1['Region'].unique())\n",
    "## Faux pays : ceux qui n'ont pas de vraix regions\n",
    "faux_pays = df1[df1['Region'].isna()]['Country Code'].tolist()\n",
    "print(\"Faux pays détectés :\", faux_pays)\n",
    "df_vrai_pays =df1[~df1['Country Code'].isin(faux_pays)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eea27d2-7aa1-4ec5-b554-166d2c301f50",
   "metadata": {},
   "source": [
    "## Fichier EdStatsCountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733987d-f226-4ff8-ab02-4ce1cde451c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#chargement du fichier \n",
    "df2 = pd.read_csv('EdStatsCountry-Series.csv')  \n",
    "#Aperçu des premières lignes : table de correspondance, un ligne représente une combinaison des deux (pays/indicateur )\n",
    "df2.head()\n",
    "# 1. Nombre de lignes et colonnes \n",
    "dim_df2 = df2.shape\n",
    "print(\"le nombre de ligne et colone de data Frame 2 df2 est :\" ,dim_df2)\n",
    "# 2. Nombre de doublons\n",
    "df2_doublons=df2.duplicated().sum()\n",
    "print ('le nombre de doublons dans la data frame 2 est :',df2_doublons)\n",
    "# 3. Suppression des doublons (si présents)\n",
    "if df2_doublons > 0 :\n",
    "   df2=df2.drop_duplicates() \n",
    "   print(f\"{df2_doublons} doublons supprimés.\")\n",
    "# 4. Proportion de valeurs manquantes par colonne\n",
    "print(\"Proportion de valeurs manquantes par colonne :\")\n",
    "print(df2.isna().mean().sort_values(ascending=False))\n",
    "\n",
    "#  5. Identifier les colonnes inutilisables (ex. entièrement vides)\n",
    "print(\"Types des colonnes :\")\n",
    "print(df2.dtypes)\n",
    "\n",
    "# Suppression des colonnes vides ou sans information utile\n",
    "cols_to_drop = df2.columns[df2.isna().mean() > 0.95]\n",
    "df2.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# 6. Statistiques descriptives pour les colonnes numériques\n",
    "print(\"Statistiques descriptives des colonnes numériques :\")\n",
    "print(df2.describe())\n",
    "\n",
    "# 7. Occurrences pour chaque valeur des colonnes catégorielles\n",
    "print(\"Valeurs uniques pour les colonnes catégorielles :\")\n",
    "for col in df2.select_dtypes(include='object').columns:\n",
    "    print(f\"Occurrences pour la colonne '{col}' :\")\n",
    "    print(df2[col].value_counts(dropna=False))  # inclut les NaN\n",
    "    print(\"-------------\")\n",
    "    \n",
    "### Nettoyage de country df2 -1er méthode  ###\n",
    "df2_vrai_pays =df2[~df2['CountryCode'].isin(faux_pays)]\n",
    "\n",
    "### Nettoyage pays -2eme méthode  ###\n",
    "df2_data_clean = df2.merge(df_vrai_pays, left_on='CountryCode',right_on='Country Code' ,how='inner')\n",
    "display(df2.shape[0])\n",
    "display(df2_data_clean.shape[0])\n",
    "display(df2_vrai_pays.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480ee7b-4a93-45c4-9345-f14ff0324b63",
   "metadata": {},
   "source": [
    "## Fichier EdStatsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7739fe3b-3203-4dcf-9baf-add386683e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chargement du fichier  df3\n",
    "df3 = pd.read_csv('EdStatsData.csv') \n",
    "# Aperçu des premières lignes : Contient les données réelles chiffrées (les valeurs) par pays, indicateur et année\n",
    "display(df3.head())\n",
    "# 1. Nombre de lignes et colonnes\n",
    "dim_df3 = df3.shape\n",
    "print(\"le nombre de ligne et colone de data Frame 3 df3 est :\" ,dim_df3)\n",
    "# 2. Nombre de doublons\n",
    "df3_doublons=df3.duplicated().sum()\n",
    "print ('le nombre de doublons dans la data frame 3 est :',df3_doublons)\n",
    "\n",
    "# 3. Suppression des doublons (si présents)\n",
    "\n",
    "if df3_doublons > 0 :\n",
    "   df3=df3.drop_duplicates() \n",
    "   print(f\"{df3_doublons} doublons supprimés.\")\n",
    "    \n",
    "# 4. Proportion de valeurs manquantes par colonne\n",
    "\n",
    "print(\"Proportion de valeurs manquantes par colonne :\")\n",
    "print(df3.isna().mean().sort_values(ascending=False))\n",
    "\n",
    "#  5. Identifier les colonnes inutilisables (ex. entièrement vides)\n",
    "print(\"Types des colonnes :\")\n",
    "print(df3.dtypes)\n",
    "\n",
    "# Suppression des colonnes vides ou sans information utile\n",
    "cols_to_drop = df3.columns[df3.isna().mean() > 0.95]\n",
    "df3.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# 6. Statistiques descriptives pour les colonnes numériques\n",
    "print(\"Statistiques descriptives des colonnes numériques :\")\n",
    "print(df3.describe())\n",
    "\n",
    "# 7. Occurrences pour chaque valeur des colonnes catégorielles\n",
    "print(\"Valeurs uniques pour les colonnes catégorielles :\")\n",
    "for col in df3.select_dtypes(include='object').columns:\n",
    "    print(f\"Occurrences pour la colonne '{col}' :\")\n",
    "    print(df3[col].value_counts(dropna=True))  # non inclut les NaN\n",
    "    print(\"-------------\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd03b028-203d-4eae-9c02-657111673b3d",
   "metadata": {},
   "source": [
    "Nettoyage des pays non valides du fichier EdStatsData\n",
    "Objectif\n",
    "Éliminer les lignes du dataframe df3 correspondant à des entités qui ne sont pas de vrais pays (ex. zones géographiques, agrégats régionaux, etc.).\n",
    "\n",
    "Méthode 1 : Filtrage avec isin() et une liste de faux pays\n",
    "Une liste de faux pays (faux_pays) a été définie manuellement après l'exploration du fichier Country.\n",
    "\n",
    "On utilise isin() combiné à ~ pour exclure les lignes où la colonne Country Code fait partie de cette liste.\n",
    "\n",
    "Cela permet de conserver uniquement les données relatives à de vrais pays.\n",
    "\n",
    "df3_vrai_pays = df3[~df3['Country Code'].isin(faux_pays)]\n",
    "\n",
    "==>Cette méthode est directe et flexible, surtout si l'on a déjà une liste précise des codes à exclure.\n",
    "\n",
    "Méthode 2 : Jointure avec la table des pays valides\n",
    "Une table nettoyée contenant uniquement les vrais pays (df_vrai_pays) a été créée à partir du fichier Country.\n",
    "\n",
    "On effectue une jointure interne (inner join) entre cette table et df3 sur la colonne Country Code.\n",
    "\n",
    "Seules les lignes correspondant à des pays présents dans df_vrai_pays sont conservées.\n",
    "\n",
    "df3_data_clean = df3.merge(df_vrai_pays[['Country Code']], on='Country Code', how='inner')\n",
    "==> Cette méthode est plus robuste si la table des vrais pays a été validée correctement, et permet d'automatiser le nettoyage sur plusieurs fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f3ce56-ea35-44e5-bed2-5ef6429398e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nettoyage pays -1er méthode  ###\n",
    "#Avant filtrage\n",
    "display(df3.shape)\n",
    "df3_vrai_pays =df3[~df3['Country Code'].isin(faux_pays)]\n",
    "#Aprés filtrage: \n",
    "display(df3_vrai_pays.shape[0])\n",
    "### Nettoyage pays -2eme méthode  ###\n",
    "df3_data_clean = df3.merge(df_vrai_pays[['Country Code']], on='Country Code', how='inner')\n",
    "#display(df3_data_clean.shape)\n",
    "df3_data_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5019bd3-d9d2-427a-957f-2e40ccaa04c5",
   "metadata": {},
   "source": [
    "Dans cette étape, nous nous concentrons sur les colonnes correspondant aux années dans le fichier EdStatsData.\n",
    "\n",
    "Les années jouent un rôle central dans l’organisation des données temporelles. Il est donc important de conserver uniquement les années contenant un minimum de données disponibles afin d'assurer la qualité des analyses.\n",
    "Objectif:\n",
    "Supprimer les colonnes (années) ayant trop de valeurs manquantes.\n",
    "Méthodologie:\n",
    "On calcule la proportion de valeurs manquantes pour chaque colonne représentant une année.\n",
    "On applique un seuil de 90% :\n",
    "Toute colonne (année) ayant plus de 90% de valeurs manquantes est supprimée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21449fb6-5c83-4838-8da9-2063f13ce0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nettoyage des années :\n",
    "cols_annees = df3_data_clean.iloc[:, 4:] \n",
    "print(cols_annees.isna().mean().sort_values(ascending=False))\n",
    "cols_annees_to_drop = cols_annees.columns[cols_annees.isna().mean() > 0.90]\n",
    "df3_data_filtre = df3_data_clean.drop(columns=cols_annees_to_drop)\n",
    "display(df3_data_filtre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d77c6-6250-4cfa-a488-c6ea4ea3c7a9",
   "metadata": {},
   "source": [
    "## Fichier EdStatsFootNote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0b6a2-484e-4ef9-af40-a48194616a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier df4\n",
    "df4 = pd.read_csv('EdStatsFootNote.csv')  \n",
    "# Aperçu des premières lignes: contient des notes pour des indicateurs par pays et par année\n",
    "display(df4.head())\n",
    "# 1. Nombre de lignes et colonnes\n",
    "dim_df4 = df4.shape\n",
    "print(\"le nombre de ligne et colone de data Frame 4 df4 est :\" ,dim_df4)\n",
    "# 2. Nombre de doublons\n",
    "df4_doublons=df4.duplicated().sum()\n",
    "print ('le nombre de doublons dans la data frame 4 est :',df4_doublons)\n",
    "# 3. Suppression des doublons (si présents)\n",
    "if df4_doublons > 0 :\n",
    "   df4=df4.drop_duplicates() \n",
    "   print(f\"{df4_doublons} doublons supprimés.\")\n",
    "    \n",
    "# 4. Proportion de valeurs manquantes par colonne\n",
    "print(\"Proportion de valeurs manquantes par colonne :\")\n",
    "print(df4.isna().mean().sort_values(ascending=False))\n",
    "\n",
    "#  5. Identifier les colonnes inutilisables (ex. entièrement vides)\n",
    "print(\"Types des colonnes :\")\n",
    "print(df4.dtypes)\n",
    "\n",
    "# Suppression des colonnes vides ou sans information utile\n",
    "cols_to_drop = df4.columns[df4.isna().mean() > 0.95]\n",
    "df4.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# 6. Statistiques descriptives pour les colonnes numériques\n",
    "print(\"Statistiques descriptives des colonnes numériques :\")\n",
    "print(df4.describe())\n",
    "\n",
    "# 7. Occurrences pour chaque valeur des colonnes catégorielles\n",
    "print(\"Valeurs uniques pour les colonnes catégorielles :\")\n",
    "for col in df4.select_dtypes(include='object').columns:\n",
    "    print(f\"Occurrences pour la colonne '{col}' :\")\n",
    "    print(df4[col].value_counts(dropna=False))  # inclut les NaN\n",
    "    print(\"-------------\")\n",
    "    \n",
    "### Nettoyage de pays -1er méthode ###\n",
    "df4_vrai_pays =df4[~df4['CountryCode'].isin(faux_pays)]\n",
    "### Nettoyage de pays -2er méthode ###\n",
    "df4_data_clean = df4.merge(df_vrai_pays[['CountryCode']], on='CountryCode', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56762a17-967b-445e-942c-d77f14c7a8da",
   "metadata": {},
   "source": [
    "## Fichier EdStatsSeries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5969d7-27e3-4992-8b5d-40c2e94540b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier df5\n",
    "df5 = pd.read_csv('EdStatsSeries.csv')\n",
    "# Aperçu des premières lignes : un ligne = un indicateur\n",
    "display(df5.head())\n",
    "# 1. Nombre de lignes et colonnes\n",
    "dim_df5 = df5.shape\n",
    "print(\"le nombre de ligne et colone de data Frame 5 df5 est :\" ,dim_df5)\n",
    "# 2. Nombre de doublons\n",
    "df5_doublons=df5.duplicated().sum()\n",
    "print ('le nombre de doublons dans la data frame 5 est :',df5_doublons)\n",
    "# 3. Suppression des doublons (si présents)\n",
    "if df5_doublons > 0 :\n",
    "   df5=df5.drop_duplicates() \n",
    "   print(f\"{df5_doublons} doublons supprimés.\")\n",
    "# 4. Proportion de valeurs manquantes par colonne\n",
    "print(\"Proportion de valeurs manquantes par colonne :\")\n",
    "print(df5.isna().mean().sort_values(ascending=False))\n",
    "\n",
    "# 5. Identifier les colonnes inutilisables (ex. entièrement vides)\n",
    "print(\"Types des colonnes :\")\n",
    "print(df5.dtypes)\n",
    "\n",
    "# Suppression des colonnes vides ou sans information utile\n",
    "cols_to_drop = df5.columns[df5.isna().mean() > 0.95]\n",
    "df5.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "# 6. Statistiques descriptives pour les colonnes numériques\n",
    "print(\"Statistiques descriptives des colonnes numériques :\")\n",
    "print(df5.describe())\n",
    "\n",
    "# 7. Occurrences pour chaque valeur des colonnes catégorielles\n",
    "print(\"Valeurs uniques pour les colonnes catégorielles :\")\n",
    "for col in df5.select_dtypes(include='object').columns:\n",
    "    print(f\"Occurrences pour la colonne '{col}' :\")\n",
    "    print(df5[col].value_counts(dropna=False))  # inclut les NaN\n",
    "    print(\"-------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
